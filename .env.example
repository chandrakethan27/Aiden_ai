# OpenAI API Configuration (if using OpenAI)
# OPENAI_API_KEY=your_api_key_here

# OpenRouter API Configuration (recommended for access to multiple models)
OPENROUTER_API_KEY=your_openrouter_api_key_here
USE_OPENROUTER=true

# Model Configuration
# For OpenRouter, use format: provider/model-name
# Examples: anthropic/claude-3.5-sonnet, openai/gpt-4-turbo, google/gemini-pro
MODEL_NAME=anthropic/claude-3.5-sonnet
MAX_TOKENS=4096
TEMPERATURE=0.7

# Optional: Azure OpenAI Configuration
# AZURE_OPENAI_ENDPOINT=your_endpoint_here
# AZURE_OPENAI_API_KEY=your_azure_key_here
# AZURE_OPENAI_DEPLOYMENT=your_deployment_name

# Optional: Local Model Configuration (Ollama)
# USE_LOCAL_MODEL=false
# LOCAL_MODEL_BASE_URL=http://localhost:11434
# LOCAL_MODEL_NAME=llama2
